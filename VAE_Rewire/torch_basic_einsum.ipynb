{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8359, 0.4783, 0.5318],\n",
       "        [0.5830, 0.8979, 0.5588]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((2, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8359, 0.5830],\n",
       "        [0.4783, 0.8979],\n",
       "        [0.5318, 0.5588]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permutation of tensor\n",
    "torch.einsum('ij->ji', x)\n",
    "\n",
    "#general alternative for transpose for multiple dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8856)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total summation\n",
    "torch.einsum('ij->', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4189, 1.3762, 1.0906])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# col sum -> 2nd rule sum over that dimension which is not specified\n",
    "torch.einsum('ij->j', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8459, 2.0397])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row sum\n",
    "torch.einsum('ij->i',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2965, 0.6978, 0.1236]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix - vector multiplication\n",
    "v = torch.rand((1, 3))\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6473],\n",
       "        [0.8685]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we would do torch.matmul(x, v.t())\n",
    "torch.einsum('ij, kj-> ik', x, v)\n",
    "# we can just speccify the dimensions as we would like do not worry about reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2102, 1.2139],\n",
       "        [1.2139, 1.4584]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication x.mm(x.t())\n",
    "torch.einsum('ij, kj->ik',x, x) # 2x2: 2x3 X 3x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2102)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product first row with first row of matrix\n",
    "\n",
    "torch.einsum(\"i, i->\", x[0], x[0]) #multiply them and sum together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6686)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product with a matrix\n",
    "torch.einsum('ij, ij->', x, x) # multiply those dimensions elemet wise and sum those as we are not specifying any output dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6987, 0.2287, 0.2828],\n",
       "        [0.3399, 0.8063, 0.3122]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hadamard product (element wise multiplication)\n",
    "torch.einsum(\"ij, ij-> ij\", x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0669, 0.4257, 0.1284]) tensor([0.5581, 0.0114, 0.3320, 0.1336, 0.0481])\n"
     ]
    }
   ],
   "source": [
    "# outer product\n",
    "a = torch.rand((3))\n",
    "b = torch.rand((5))\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0373, 0.0008, 0.0222, 0.0089, 0.0032],\n",
       "        [0.2376, 0.0049, 0.1413, 0.0569, 0.0205],\n",
       "        [0.0717, 0.0015, 0.0426, 0.0172, 0.0062]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('i,j->ij',a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch matrix multiplication\n",
    "a = torch.rand((3, 2, 5))\n",
    "b = torch.rand((3, 5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4439, 0.8518, 0.0274, 0.4039, 0.9516],\n",
      "         [0.1949, 0.9648, 0.4507, 0.6531, 0.1269]],\n",
      "\n",
      "        [[0.8611, 0.3240, 0.7792, 0.3529, 0.8670],\n",
      "         [0.8588, 0.6474, 0.6506, 0.8270, 0.0866]],\n",
      "\n",
      "        [[0.4222, 0.0063, 0.0337, 0.5152, 0.3265],\n",
      "         [0.9707, 0.5304, 0.7236, 0.7062, 0.1349]]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0838, 0.3579, 0.3544],\n",
      "         [0.6477, 0.4894, 0.2690],\n",
      "         [0.6090, 0.3690, 0.7000],\n",
      "         [0.9438, 0.5963, 0.6871],\n",
      "         [0.0942, 0.5759, 0.7145]],\n",
      "\n",
      "        [[0.4368, 0.4101, 0.9316],\n",
      "         [0.3672, 0.5902, 0.3404],\n",
      "         [0.6847, 0.2392, 0.0487],\n",
      "         [0.5589, 0.1860, 0.7142],\n",
      "         [0.6228, 0.8077, 0.7029]],\n",
      "\n",
      "        [[0.2053, 0.1460, 0.2728],\n",
      "         [0.2852, 0.8216, 0.6679],\n",
      "         [0.5862, 0.7638, 0.1191],\n",
      "         [0.2173, 0.2636, 0.5727],\n",
      "         [0.7716, 0.6807, 0.8176]]])\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0765, 1.3747, 1.3631],\n",
       "         [1.5441, 1.1708, 1.1835]],\n",
       "\n",
       "        [[1.7659, 1.4967, 1.8119],\n",
       "         [1.5746, 1.1136, 1.7037]],\n",
       "\n",
       "        [[0.4721, 0.4506, 0.6854],\n",
       "         [1.0323, 1.4081, 1.2199]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ijk, ikl->ijl\", a, b) # here i and k needs to match\n",
    "# we can also to torch.bmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6032, 0.2361, 0.4647],\n",
       "        [0.2148, 0.2407, 0.6258],\n",
       "        [0.0011, 0.2426, 0.1901]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix diagonal\n",
    "x = torch.rand((3,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6032, 0.2407, 0.1901])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ii->i\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0340)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix trace\n",
    "torch.einsum(\"ii->\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
