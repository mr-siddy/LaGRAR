{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.datasets import WebKB, Planetoid, WikipediaNetwork\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "#from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WebKB(root=\"/home/siddy/META/data\", name=\"Cornell\")\n",
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[183, 1703], edge_index=[2, 298], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index= data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomLinkSplit(is_undirected=True, add_negative_train_samples=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[183, 1703], edge_index=[2, 236], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], edge_label=[118], edge_label_index=[2, 118])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[183, 1703], edge_index=[2, 236], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], edge_label=[32], edge_label_index=[2, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[183, 1703], edge_index=[2, 268], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], edge_label=[66], edge_label_index=[2, 66])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_train = train_data.x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_index(num_nodes, edge_index):\n",
    "    adj_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.long)\n",
    "    for i in range(edge_index.size(1)):\n",
    "        u, v = int(edge_index[0, i]), int(edge_index[1, i])\n",
    "        adj_matrix[u, v] = 1\n",
    "        adj_matrix[v, u] = 1\n",
    "\n",
    "    neg_indices = []\n",
    "    for i in range(edge_index.size(1)):\n",
    "        u, v = int(edge_index[0, i]), int(edge_index[1, i])\n",
    "        adj_squared = torch.mm(adj_matrix, adj_matrix)\n",
    "        adj_row_u = adj_matrix[u]\n",
    "        adj_row_v = adj_matrix[v]\n",
    "        bitwise_and_result = torch.bitwise_and(adj_squared[u], adj_squared[v])\n",
    "        sum_bitwise_and_result = torch.sum(bitwise_and_result)\n",
    "        sum_adj_u = torch.sum(adj_row_u)\n",
    "        sum_adj_v = torch.sum(adj_row_v)\n",
    "        neg_index = sum_bitwise_and_result.float() / (sum_adj_u + sum_adj_v)\n",
    "        neg_indices.append(neg_index.item())\n",
    "\n",
    "    return neg_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_index(num_nodes, edge_index):\n",
    "    adj_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.long)\n",
    "    for i in range(edge_index.size(1)):\n",
    "        u, v = int(edge_index[0, i]), int(edge_index[1, i])\n",
    "        adj_matrix[u, v] = 1\n",
    "        adj_matrix[v, u] = 1\n",
    "\n",
    "    pos_indices = []\n",
    "    for i in range(edge_index.size(1)):\n",
    "        u, v = int(edge_index[0, i]), int(edge_index[1, i])\n",
    "        adj_row_u = adj_matrix[u]\n",
    "        adj_row_v = adj_matrix[v]\n",
    "        bitwise_and_result = torch.bitwise_and(adj_row_u, adj_row_v)\n",
    "        sum_bitwise_and_result = torch.sum(bitwise_and_result)\n",
    "        sum_adj_u = torch.sum(adj_row_u)\n",
    "        sum_adj_v = torch.sum(adj_row_v)\n",
    "        pos_index = sum_bitwise_and_result.float() / (sum_adj_u + sum_adj_v)\n",
    "        pos_indices.append(pos_index.item())\n",
    "\n",
    "    return pos_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.empty(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # what is the shape of inpur x ? - needed [N, in_channels]\n",
    "        # edge indices shape needed is [2, E]\n",
    "\n",
    "        #add self_loops to the adjacency matrix, how to give num nodes?\n",
    "        #edge_index, _ = add_self_loops(edge_index)\n",
    "        #print(edge_index)\n",
    "        # linearly transform node feature matrix\n",
    "        x = self.lin(x)\n",
    "        #x = torch.index_select(input=x, index=edge_index[0], dim=0)\n",
    "        # x_ball = torch.cat([torch.index_select(input=x, index=edge_index[0], dim=0), NOTE THAT IT WILL GIVE INDEX OUT OF RANGE ONE OPTION IS TO GO WITH REINDEXING\n",
    "        #             torch.index_select(input=x, index=edge_index[1], dim=0)],dim=0)\n",
    "        #compute normalization\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt==float('inf')] = 0\n",
    "        #print(deg_inv_sqrt.shape)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # propagating messages\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "        #out = torch.index_select(input=out, index=min(edge_index[0]), dim=0) #NOTE TRICK IS TO PICK MIN EDGE INDEX AS IT WILL CORRESPOND TO THE CENTER NODE OF THE BALL\n",
    "        # bias\n",
    "        out += self.bias\n",
    "        return torch.squeeze(out)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # normalize node features\n",
    "        return norm.view(-1,1) *x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNNet(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = GCNConv(in_channels, hidden_channels)\n",
    "        self.fc = Linear(hidden_channels, out_channels)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc(self.conv(x, edge_index))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = 0.005, 0.005\n",
    "def custom_objective(sigma_1, sigma_2):\n",
    "    return (alpha*sigma_1 - 0.5)**2 + beta*sigma_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self,x ,edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels= dataset.num_classes\n",
    "num_features = dataset.num_features\n",
    "epochs=100\n",
    "neg_indices = neg_index(num_nodes_train, train_data.edge_index)\n",
    "pos_indices = pos_index(num_nodes_train, train_data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = []\n",
    "for i in range(train_data.edge_index.size(1)):\n",
    "        #u, v = int(data.edge_index[0, i]), int(data.edge_index[1, i])\n",
    "        #current_pair\n",
    "    sigma_1= torch.tensor(neg_indices[i], requires_grad=True)\n",
    "    sigma_2 = torch.tensor(pos_indices[i], requires_grad=True)\n",
    "    objective = custom_objective(sigma_1, sigma_2)\n",
    "    obj.append(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 236)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(train_data.edge_index.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(GCNEncoder(num_features, out_channels))\n",
    "gcn_net = GCNNet(in_channels=data.x.size(1), hidden_channels=64, out_channels=dataset.num_classes)\n",
    "gcn_net = gcn_net.to(device)\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "optimizer = torch.optim.Adam(list(model.parameters())+ list(gcn_net.parameters()), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, neg_indices, pos_indices):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index= train_data.edge_index,\n",
    "        num_nodes= train_data.x.size(0),\n",
    "        num_neg_samples=train_data.edge_index.size(1)\n",
    "    )\n",
    "    # neg_indices = neg_index(num_nodes_train, train_data.edge_index)\n",
    "    # pos_indices = pos_index(num_nodes_train, train_data.edge_index)\n",
    "    z = model.encode(x, train_data.edge_index)\n",
    "    #print(f\"latent space shape: {z.shape}\")\n",
    "    #adj = torch.sigmoid(torch.matmul(z, z.t()))\n",
    "    #print(f\"adj matrix shape: {adj.shape}\")\n",
    "    #loss = model.recon_loss(z, train_data.edge_index)\n",
    "    loss = (1 / data.num_nodes) * model.kl_loss()  # new line\n",
    "    #adj_binary = (adj > 0.5).float()\n",
    "    #edge_list = adj.nonzero(as_tuple=False)\n",
    "    #edge_list = torch.permute(torch.tensor(edge_list, dtype=torch.long), (1,0)).to(device)\n",
    "    # neg_indices = neg_index(num_nodes_train, train_data.edge_list)\n",
    "    # pos_indices = pos_index(num_nodes_train, train_data.edge_list)\n",
    "    for i in range(len(neg_indices)):\n",
    "        sigma_1 = torch.tensor(neg_indices[i], requires_grad=True)\n",
    "        sigma_2 = torch.tensor(pos_indices[i], requires_grad=True)\n",
    "        objective = custom_objective(sigma_1, sigma_2)\n",
    "        loss += objective\n",
    "    out = gcn_net(train_data.x, train_data.edge_index)\n",
    "    nc_loss = F.cross_entropy(out[train_data.train_mask[:,0]], train_data.y[train_data.train_mask[:,0]])\n",
    "    loss += nc_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(test_data):\n",
    "    model.eval()\n",
    "    gcn_net.eval()\n",
    "    with torch.no_grad():\n",
    "        test_neg_edge_index = negative_sampling(\n",
    "            edge_index= test_data.edge_index,\n",
    "            num_nodes= test_data.x.size(0),\n",
    "            num_neg_samples=test_data.edge_index.size(1)\n",
    "        )\n",
    "        z = model.encode(x, test_data.edge_index)\n",
    "        out = \n",
    "        accs=[]\n",
    "        accs.append(int())\n",
    "    \n",
    "    return model.test(z, test_data.edge_index, test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_train = train_data.x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.67121505737305\n",
      "Epoch: 001, AUC: 0.5130, AP: 0.5084\n",
      "59.56915283203125\n",
      "Epoch: 002, AUC: 0.5111, AP: 0.5075\n",
      "59.63116455078125\n",
      "Epoch: 003, AUC: 0.5148, AP: 0.5093\n",
      "59.61537170410156\n",
      "Epoch: 004, AUC: 0.5056, AP: 0.5047\n",
      "59.570648193359375\n",
      "Epoch: 005, AUC: 0.5185, AP: 0.5113\n",
      "59.53494644165039\n",
      "Epoch: 006, AUC: 0.5148, AP: 0.5093\n",
      "59.57355499267578\n",
      "Epoch: 007, AUC: 0.5074, AP: 0.5056\n",
      "59.575401306152344\n",
      "Epoch: 008, AUC: 0.5074, AP: 0.5056\n",
      "59.55477523803711\n",
      "Epoch: 009, AUC: 0.5037, AP: 0.5037\n",
      "59.565792083740234\n",
      "Epoch: 010, AUC: 0.5093, AP: 0.5065\n",
      "59.5667839050293\n",
      "Epoch: 011, AUC: 0.5093, AP: 0.5065\n",
      "59.614925384521484\n",
      "Epoch: 012, AUC: 0.5185, AP: 0.5113\n",
      "59.58082962036133\n",
      "Epoch: 013, AUC: 0.5074, AP: 0.5056\n",
      "59.59929656982422\n",
      "Epoch: 014, AUC: 0.5093, AP: 0.5065\n",
      "59.60763168334961\n",
      "Epoch: 015, AUC: 0.5037, AP: 0.5037\n",
      "59.61659622192383\n",
      "Epoch: 016, AUC: 0.5074, AP: 0.5056\n",
      "59.58620834350586\n",
      "Epoch: 017, AUC: 0.5093, AP: 0.5065\n",
      "59.56905746459961\n",
      "Epoch: 018, AUC: 0.5074, AP: 0.5056\n",
      "59.58341979980469\n",
      "Epoch: 019, AUC: 0.5111, AP: 0.5075\n",
      "59.56840896606445\n",
      "Epoch: 020, AUC: 0.5056, AP: 0.5047\n",
      "59.6019401550293\n",
      "Epoch: 021, AUC: 0.5130, AP: 0.5084\n",
      "59.530906677246094\n",
      "Epoch: 022, AUC: 0.5111, AP: 0.5075\n",
      "59.54499053955078\n",
      "Epoch: 023, AUC: 0.5074, AP: 0.5056\n",
      "59.54014587402344\n",
      "Epoch: 024, AUC: 0.5056, AP: 0.5047\n",
      "59.55287551879883\n",
      "Epoch: 025, AUC: 0.5056, AP: 0.5047\n",
      "59.536766052246094\n",
      "Epoch: 026, AUC: 0.5056, AP: 0.5047\n",
      "59.5546989440918\n",
      "Epoch: 027, AUC: 0.5111, AP: 0.5075\n",
      "59.52842330932617\n",
      "Epoch: 028, AUC: 0.5093, AP: 0.5065\n",
      "59.54706573486328\n",
      "Epoch: 029, AUC: 0.5093, AP: 0.5065\n",
      "59.5516471862793\n",
      "Epoch: 030, AUC: 0.5130, AP: 0.5084\n",
      "59.62651443481445\n",
      "Epoch: 031, AUC: 0.5074, AP: 0.5056\n",
      "59.566734313964844\n",
      "Epoch: 032, AUC: 0.5093, AP: 0.5065\n",
      "59.530181884765625\n",
      "Epoch: 033, AUC: 0.5111, AP: 0.5075\n",
      "59.517478942871094\n",
      "Epoch: 034, AUC: 0.5093, AP: 0.5065\n",
      "59.53999328613281\n",
      "Epoch: 035, AUC: 0.5111, AP: 0.5075\n",
      "59.55641555786133\n",
      "Epoch: 036, AUC: 0.5130, AP: 0.5084\n",
      "59.574607849121094\n",
      "Epoch: 037, AUC: 0.5074, AP: 0.5056\n",
      "59.52334213256836\n",
      "Epoch: 038, AUC: 0.5111, AP: 0.5075\n",
      "59.56171417236328\n",
      "Epoch: 039, AUC: 0.5093, AP: 0.5065\n",
      "59.61063003540039\n",
      "Epoch: 040, AUC: 0.5111, AP: 0.5075\n",
      "59.53656005859375\n",
      "Epoch: 041, AUC: 0.5056, AP: 0.5047\n",
      "59.58714294433594\n",
      "Epoch: 042, AUC: 0.5074, AP: 0.5056\n",
      "59.51953125\n",
      "Epoch: 043, AUC: 0.5093, AP: 0.5065\n",
      "59.53335189819336\n",
      "Epoch: 044, AUC: 0.5056, AP: 0.5047\n",
      "59.52775955200195\n",
      "Epoch: 045, AUC: 0.5111, AP: 0.5075\n",
      "59.51325607299805\n",
      "Epoch: 046, AUC: 0.5093, AP: 0.5065\n",
      "59.56922149658203\n",
      "Epoch: 047, AUC: 0.5074, AP: 0.5056\n",
      "59.53812026977539\n",
      "Epoch: 048, AUC: 0.5056, AP: 0.5047\n",
      "59.629737854003906\n",
      "Epoch: 049, AUC: 0.5148, AP: 0.5093\n",
      "59.530189514160156\n",
      "Epoch: 050, AUC: 0.5111, AP: 0.5075\n",
      "59.56146240234375\n",
      "Epoch: 051, AUC: 0.5148, AP: 0.5093\n",
      "59.55226135253906\n",
      "Epoch: 052, AUC: 0.5056, AP: 0.5047\n",
      "59.52824401855469\n",
      "Epoch: 053, AUC: 0.5185, AP: 0.5113\n",
      "59.57259750366211\n",
      "Epoch: 054, AUC: 0.5093, AP: 0.5065\n",
      "59.50686264038086\n",
      "Epoch: 055, AUC: 0.5037, AP: 0.5037\n",
      "59.525901794433594\n",
      "Epoch: 056, AUC: 0.5074, AP: 0.5056\n",
      "59.521148681640625\n",
      "Epoch: 057, AUC: 0.5093, AP: 0.5065\n",
      "59.52163314819336\n",
      "Epoch: 058, AUC: 0.5093, AP: 0.5065\n",
      "59.524688720703125\n",
      "Epoch: 059, AUC: 0.5111, AP: 0.5075\n",
      "59.54926681518555\n",
      "Epoch: 060, AUC: 0.5093, AP: 0.5065\n",
      "59.511940002441406\n",
      "Epoch: 061, AUC: 0.5074, AP: 0.5056\n",
      "59.534488677978516\n",
      "Epoch: 062, AUC: 0.5093, AP: 0.5065\n",
      "59.64779281616211\n",
      "Epoch: 063, AUC: 0.5056, AP: 0.5047\n",
      "59.53341293334961\n",
      "Epoch: 064, AUC: 0.5093, AP: 0.5065\n",
      "59.508338928222656\n",
      "Epoch: 065, AUC: 0.5093, AP: 0.5065\n",
      "59.51304626464844\n",
      "Epoch: 066, AUC: 0.5074, AP: 0.5056\n",
      "59.52555465698242\n",
      "Epoch: 067, AUC: 0.5111, AP: 0.5075\n",
      "59.51423263549805\n",
      "Epoch: 068, AUC: 0.5148, AP: 0.5093\n",
      "59.52967834472656\n",
      "Epoch: 069, AUC: 0.5130, AP: 0.5084\n",
      "59.51868438720703\n",
      "Epoch: 070, AUC: 0.5037, AP: 0.5037\n",
      "59.59054183959961\n",
      "Epoch: 071, AUC: 0.5074, AP: 0.5056\n",
      "59.56776809692383\n",
      "Epoch: 072, AUC: 0.5074, AP: 0.5056\n",
      "59.514976501464844\n",
      "Epoch: 073, AUC: 0.5093, AP: 0.5065\n",
      "59.50590896606445\n",
      "Epoch: 074, AUC: 0.5111, AP: 0.5075\n",
      "59.543643951416016\n",
      "Epoch: 075, AUC: 0.5111, AP: 0.5075\n",
      "59.515296936035156\n",
      "Epoch: 076, AUC: 0.5111, AP: 0.5075\n",
      "59.533714294433594\n",
      "Epoch: 077, AUC: 0.5093, AP: 0.5065\n",
      "59.50345993041992\n",
      "Epoch: 078, AUC: 0.5167, AP: 0.5103\n",
      "59.517513275146484\n",
      "Epoch: 079, AUC: 0.5074, AP: 0.5056\n",
      "59.50413131713867\n",
      "Epoch: 080, AUC: 0.5093, AP: 0.5065\n",
      "59.53825759887695\n",
      "Epoch: 081, AUC: 0.5130, AP: 0.5084\n",
      "59.560569763183594\n",
      "Epoch: 082, AUC: 0.5093, AP: 0.5065\n",
      "59.51759719848633\n",
      "Epoch: 083, AUC: 0.5093, AP: 0.5065\n",
      "59.52614212036133\n",
      "Epoch: 084, AUC: 0.5074, AP: 0.5056\n",
      "59.56801223754883\n",
      "Epoch: 085, AUC: 0.5056, AP: 0.5047\n",
      "59.54301834106445\n",
      "Epoch: 086, AUC: 0.5130, AP: 0.5084\n",
      "59.51881408691406\n",
      "Epoch: 087, AUC: 0.5074, AP: 0.5056\n",
      "59.54446029663086\n",
      "Epoch: 088, AUC: 0.5056, AP: 0.5047\n",
      "59.53596878051758\n",
      "Epoch: 089, AUC: 0.5093, AP: 0.5065\n",
      "59.54778289794922\n",
      "Epoch: 090, AUC: 0.5093, AP: 0.5065\n",
      "59.50507354736328\n",
      "Epoch: 091, AUC: 0.5111, AP: 0.5075\n",
      "59.53424835205078\n",
      "Epoch: 092, AUC: 0.5111, AP: 0.5075\n",
      "59.537513732910156\n",
      "Epoch: 093, AUC: 0.5093, AP: 0.5065\n",
      "59.563167572021484\n",
      "Epoch: 094, AUC: 0.5148, AP: 0.5093\n",
      "59.53096008300781\n",
      "Epoch: 095, AUC: 0.5130, AP: 0.5084\n",
      "59.53501510620117\n",
      "Epoch: 096, AUC: 0.5130, AP: 0.5084\n",
      "59.49702453613281\n",
      "Epoch: 097, AUC: 0.5111, AP: 0.5075\n",
      "59.49764633178711\n",
      "Epoch: 098, AUC: 0.5037, AP: 0.5037\n",
      "59.5158805847168\n",
      "Epoch: 099, AUC: 0.5111, AP: 0.5075\n",
      "59.520538330078125\n",
      "Epoch: 100, AUC: 0.5093, AP: 0.5065\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(train_data, neg_indices, pos_indices)\n",
    "    print(loss)\n",
    "    auc, ap = test(test_data)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
